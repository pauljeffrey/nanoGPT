# takes 54GB in huggingface .cache dir, about 8M documents (8,013,769)
    #dataset = load_dataset("openwebtext", num_proc=num_proc_load_dataset)
    # Don't use 0, 9, 28| 1,2,23,31,17,15,16, 18
    # data_files = [
    #     "data/train-00032-of-00035-65723db2a29abae8.parquet","data/train-00033-of-00035-bcb2a36aebfb89f9.parquet",
    #               "data/train-00034-of-00035-3244e25f0c60266d.parquet","data/train-00029-of-00035-4fda4ad62c4ffb34.parquet",
    #               "data/train-00030-of-00035-7722c3ba07048ce8.parquet",]
    # download_config = datasets.DownloadConfig(force_download=True)
    # #https://huggingface.co/datasets/vietgpt/the_pile_openwebtext2/blob/main/data/



